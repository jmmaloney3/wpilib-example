# Code Team Meeting Agenda - Beginning of Season

## Overview
This agenda covers the organization, processes, and standards for the FRC code team. Topics are organized by theme to facilitate discussion and decision-making.

---

## 1. Development Workflow & Git Strategy

### 1.1 Branching Strategy Decision
**Key Question: Feature branches with PRs vs. direct commits to main?**

- **Option A: Feature branches with Pull Requests (Recommended)** [^1][^2][^3]
  - All changes go through feature branches
  - PR required for all merges to main
  - Enables code review before integration
  - Aligns with trunk-based development best practices
  - Short-lived branches (hours to days, not weeks)
  **Meeting Topics for Beginning of Season Code Team**

- Github Organization
    - Pull requests
        - What information should be included in the pull request?
        - Pull request template
    - Code reviews
    - Identify “code owners”?
    - Branch management
    - Merge Conflicts
    - Spotless - require Spotless before merging to main?
- Configuration Management
    - .gitignore
    - In general, generated files (such as .class files) should not be checked into git - unless there is a special reason why we need to store the class files
    - Identify which files should be managed in git and which files shoujld be downloaded or generated by the build process
- Design
    - Design before coding
- Coding standards
    - Spotless?
- Iterative Development
    - Make small, frequent changes
        - Easier to debug problems
        - Only implement what is actually required to meet the immediate goal
        - After “seeing” your code in action, you often change the design for the next phase of the project
        - So, test small changes, then make appropriate changes for the next phase
    - MVP - most valuable product
    - “You’re not going to need it”
- Testing
    - Automated regression testing?
    - Can we do **any** testing independent of hardware?
- Refactoring Drivebase Code
- AI Usage in code
- Order of operations and subgroups + people management
    - Who is here for what days
    - “Coding pairs”
    - coding drivebase vs individual parts
        - all together or separate
    - Group coding
    - Electronics
- Schedule & Milestones
    - “The Big Spreadsheet”
    - What are the milestones for the code team?
    - How do these relate to the other teams (mechanical build, etc)
- Mentor participation
    - How do mentors participate?  “Show how”? Pair programming? Code reviews?
    - How do mentors provide guidance - especially when mentors think the team might be going in the wrong direction or making a “bad decision”?
    - Mentors provide significant guidance which tapers off as the season progresses?
- Update code to new WPILib version
    - Use AI to do the upgrade? At least the first pass - with team code review?

### Development Process

- Requirements
    - What do we want the robot to do?
    - Where are these documented?
- Planning
    - Break requirements down into small “increments”
    - Tickets/Stories to document acceptance criteria (requirements for the increment)
- Design
    - How are we going to make the robot do that?
    - How do we document designs?
- Implementation
    - Write the code
    - Code standards?  Naming conventions?
    - Code architecture
- Stand Up Meetings
    - Do we have daily stand-ups?
- Test on laptop before submitting code
    - How do we test the code on a laptop?
        - How do we do some “sanity checks” (aka, “smoke tests”) on a developer’s laptop to ensure that some basic functionality hasn’t been broken?
        - Can we create a basic set of automated tests that ensure that basic operations still work after a change?
    - Use the simulator?
- Submit the code to Git
    - Code Review
        - Pull Request?
        - Code owners? Do we have “owners” for different parts of the code base? Are they required to review code for those areas? What if they are unavailable?
    - CI/CD pipeline with automated tests?
        - Can we implement automated tests for the robot code?
        - At least run the gradle build script to ensure the code compiles?
- Deploy the code to the robot
- Test code on robot (Quality Control/Assurance)
    - Do we have a test script that we use to ensure that all code and features are tested to verify that they are still working?
    - Test script is augmented with new steps as new features are added
- “Hot Fixes” at matches
    - How do we do this?
    - Do we need to override the branch protection rules?
    - Or can we do quick code reviews?
- **Option B: Direct commits to main**
  - Faster for small changes
  - Requires high trust and discipline
  - Less protection against breaking changes
  - May conflict with branch protection rules

**Discussion Points:**
- Team size and experience level
- How to handle urgent fixes during matches
- Balance between speed and code quality
- Whether branch protection rules allow direct commits

### 1.2 Pull Requests & Code Reviews
- **PR Requirements:**
  - What information should be included? (What, Why, Testing done)
  - PR template for consistency
  - Required reviewers before merge
  - Link to related issues/tickets
  
- **Code Review Process:**
  - Who reviews what?
  - Code owners for different subsystems (drivetrain, arm, autonomous, etc.)
  - What if code owner is unavailable?
  - Review turnaround time expectations
  - How to handle review feedback

### 1.3 Branch Management
- Short-lived feature branches (aligns with trunk-based development) [^1]
- Branch naming conventions (`feature/`, `fix/`, `refactor/`)
- Regular merging from main to feature branches to prevent conflicts
- Delete branches after merge

### 1.4 Merge Conflicts
- Prevention strategies (frequent integration, small changes)
- Resolution process when conflicts occur
- Who resolves conflicts?

### 1.5 Code Quality Gates
- **Spotless** - Require passing Spotless before merging to main?
- Automated checks in CI/CD pipeline
- What blocks a merge? (Tests, linting, reviews)

---

## 2. Configuration Management

### 2.1 .gitignore Strategy
- Generated files should NOT be committed (`.class` files, build artifacts)
- Exception: When do we need to commit generated files? (Rare cases)
- Keep `.gitignore` comprehensive and up-to-date

### 2.2 File Management
- **Tracked in Git:**
  - Source code (`.java` files)
  - Configuration files
  - Documentation
  - Build configuration (Gradle files)
  
- **NOT Tracked (generated/downloaded):**
  - Compiled classes
  - Build artifacts
  - Vendor dependencies (handled by Gradle)
  - IDE-specific files (unless team standardizes)

---

## 3. Development Practices

### 3.1 Design Before Coding
- When is design required? (For new subsystems? Small changes?)
- How do we document designs?
- Design review process?

### 3.2 Iterative Development
- **Small, frequent changes:**
  - Easier to debug
  - Only implement what's needed for immediate goal
  - Test, then iterate based on results
  
- **MVP (Minimum Viable Product)**
  - Start simple, add complexity as needed
  
- **YAGNI (You Aren't Gonna Need It)**
  - Avoid over-engineering
  - Build for current needs, not hypothetical future needs

### 3.3 Coding Standards
- **Code formatting:**
  - Spotless configuration
  - Auto-format on commit or in CI?
  
- **Naming conventions:**
  - Classes, methods, variables
  - Constants
  - Packages
  
- **Code architecture:**
  - Subsystem structure
  - Command-based architecture (WPILib)
  - Separation of concerns

---

## 4. Testing Strategy

### 4.1 Testing on Development Machines
- **Smoke tests / Sanity checks:**
  - What basic functionality should always work?
  - Can we automate these checks?
  
- **Simulator usage:**
  - When to use simulator?
  - What can be tested in simulator?
  - Limitations of simulator testing

### 4.2 Automated Testing
- **What can be tested without hardware?**
  - Unit tests for calculations (PID, kinematics)
  - Logic tests for state machines
  - Integration tests in simulator
  
- **CI/CD Pipeline:**
  - Run Gradle build to ensure code compiles
  - Run automated tests
  - Run Spotless checks
  - What happens if tests fail?

### 4.3 Testing on Robot (QA)
- **Test script/checklist:**
  - Standard test procedure before deploying
  - Verify all features still work
  - Update test script as features are added
  
- **Who performs robot testing?**
- **When is code "ready" for robot?**

---

## 5. Development Process

### 5.1 Requirements & Planning
- **Requirements documentation:**
  - What do we want the robot to do?
  - Where are requirements documented? (Issues, tickets, docs?)
  
- **Breaking down work:**
  - Small increments/tickets/stories
  - Acceptance criteria for each increment
  - How to prioritize work?

### 5.2 Design Documentation
- How do we document designs?
- Design reviews before implementation?
- Architecture decisions recorded?

### 5.3 Implementation Standards
- Code standards (covered in section 3.3)
- Code architecture (covered in section 3.3)
- When to refactor vs. when to ship?

### 5.4 Stand-Up Meetings
- Do we have daily stand-ups?
- Format: What did you do? What will you do? Blockers?
- How long? When?

### 5.5 Deployment Process
- **Before submitting to Git:**
  - Test on laptop/simulator
  - Run local checks (build, Spotless)
  
- **Submit to Git:**
  - Create branch (if using feature branches)
  - Create PR
  - Code review
  
- **Deploy to robot:**
  - Process for deploying approved code
  - Who deploys?
  - Verification after deployment

---

## 6. Team Organization & Management

### 6.1 Team Structure
- **Subgroups:**
  - Drivetrain team
  - Manipulator/arm team
  - Autonomous team
  - Vision team
  - Other subsystems?
  
- **Coding pairs:**
  - When to pair program?
  - How are pairs assigned?
  
- **Group coding:**
  - When does the whole team code together?
  - How to coordinate?

### 6.2 Scheduling & Availability
- Who is available on which days?
- How to track availability?
- "The Big Spreadsheet" - what is it? How do we use it?

### 6.3 Milestones & Integration
- **Code team milestones:**
  - What are the key milestones?
  - Timeline for each milestone?
  
- **Integration with other teams:**
  - How do code milestones align with mechanical build?
  - When do we need hardware to test?
  - Communication with mechanical/electrical teams

---

## 7. Mentor Participation

### 7.1 Mentor Roles
- **How do mentors participate?**
  - "Show how" - demonstrate techniques
  - Pair programming with students
  - Code reviews
  - Architecture guidance
  
- **Guidance approach:**
  - How to provide guidance when team might be going wrong direction?
  - How to handle "bad decisions"?
  - When to step in vs. let students learn from mistakes?
  
- **Mentor involvement over time:**
  - Significant guidance early in season
  - Taper off as season progresses
  - Students take more ownership

### 7.2 Code Reviews by Mentors
- Do mentors review all code?
- Do mentors approve PRs?
- How to balance learning vs. code quality?

---

## 8. Special Topics

### 8.1 Refactoring Drivebase Code
- Is this a specific project?
- When to refactor vs. when to ship?
- How to plan refactoring work?

### 8.2 AI Usage in Code
- **When is AI appropriate?**
  - Code generation?
  - Debugging help?
  - Documentation?
  
- **Guidelines:**
  - Always review AI-generated code
  - Understand what AI code does
  - Don't blindly copy-paste
  - Use AI as a tool, not a replacement for learning

### 8.3 WPILib Version Updates
- **Upgrading to new WPILib version:**
  - Use AI for first pass? (With team code review)
  - Manual upgrade process?
  - Testing after upgrade?
  - When to upgrade? (During season vs. off-season)

### 8.4 Hot Fixes During Matches
- **Process for urgent fixes:**
  - How to handle critical bugs during competition?
  - Quick code review process?
  - Override branch protection rules? (If using them)
  - Emergency deployment process?
  
- **Prevention:**
  - How to reduce need for hot fixes?
  - Better testing before matches?

---

## Research Insights: Top-Tier FRC Teams

Based on research into how top-performing FRC teams organize:

### Key Practices:
1. **Trunk-Based Development with Short-Lived Feature Branches** [^1][^2][^3]
   - Feature branches last hours to days, not weeks
   - Frequent integration (multiple times per day)
   - Reduces merge conflicts significantly

2. **Code Reviews via Pull Requests** [^3][^4]
   - Even in trunk-based development, PRs are used for reviews
   - Small, focused PRs for quick reviews
   - Knowledge sharing through reviews

3. **Continuous Integration** [^2][^5]
   - Automated tests run before every commit/merge
   - Build must pass before merging
   - Catches issues early

4. **Feature Flags (Advanced)** [^6]
   - Some teams use feature flags to integrate incomplete features
   - Allows work-in-progress code in main without affecting stability
   - May be overkill for smaller teams

5. **Clear Ownership**
   - Code owners for different subsystems
   - Clear responsibility for different areas

6. **Testing Strategy**
   - Unit tests for calculations and logic
   - Simulator testing for integration
   - Robot testing for final validation

---

## Recommended Decisions to Make

1. **Branching strategy** - Feature branches + PRs vs. direct commits
2. **Code review requirements** - Who reviews? Required approvals?
3. **Code quality gates** - Spotless? Automated tests? What blocks merge?
4. **Testing strategy** - What can be automated? Simulator usage?
5. **Stand-up meetings** - Frequency and format
6. **Mentor involvement** - Roles and how it changes over time
7. **Hot fix process** - How to handle urgent fixes during matches

---

## Next Steps After Meeting

1. Document decisions in team wiki/docs
2. Set up GitHub branch protection rules (if using feature branches)
3. Create PR template
4. Set up CI/CD pipeline (even if just build checks initially)
5. Create test checklist/script
6. Set up Spotless (if decided)
7. Create code owners file (if using code owners)

---

## References

[^1]: TrunkBasedDevelopment.com. "Short-Lived Feature Branches." *Trunk Based Development*. https://trunkbaseddevelopment.com/short-lived-feature-branches/

[^2]: DORA (DevOps Research and Assessment). "Trunk-Based Development." *DORA Capabilities*. https://dora.dev/capabilities/trunk-based-development/

[^3]: Marco Patino. "Pull Requests in Trunk-Based Development." *Marco Patino's Blog*. https://www.marcopatino.dev/articles/prs-trunk-based-dev

[^4]: Atlassian. "Branch Deployments in Continuous Delivery Pipelines." *Atlassian Continuous Delivery*. https://www.atlassian.com/continuous-delivery/branch-deployments-in-continuous-delivery-pipelines

[^5]: DORA (DevOps Research and Assessment). "Trunk-Based Development." *DORA Capabilities*. https://dora.dev/capabilities/trunk-based-development/

[^6]: Unleash.io. "How to Implement Trunk-Based Development: A Practical Guide." *Unleash Blog*. https://www.getunleash.io/blog/how-to-implement-trunk-based-development-a-practical-guide

### Additional Resources

- **Trunk-Based Development Guide**: See `docs/trunk-based-dev-guide.md` in this repository for detailed workflow procedures
- **Git Commands Reference**: See `docs/git-commands-reference.md` for common Git operations

### Notes on Research

The research findings are based on industry best practices for trunk-based development and continuous integration, which are commonly adopted by high-performing software development teams. While specific FRC team practices are not always publicly documented, these practices align with software engineering principles that scale well for collaborative development environments like FRC code teams.

For FRC-specific resources, consider:
- FIRST Robotics Competition forums and community discussions
- Team websites and GitHub repositories of top-performing teams (when publicly available)
- FRC programming documentation and best practices guides

